{
  "nodes": [
    {
      "id": 0,
      "text": "<processing_rules> <segmentation_rule>Split at speaker turns and major topic shifts</segmentation_rule> <reorganization_rule>Group by themes: technical discussion, resource concerns, action items</reorganization_rule> </processing_rules> <SEGMENT rule='Split at speaker turns and major topic shifts'> Meeting Discussion on AI Development Strategy Speaker A: We need to discuss our approach to building the next generation AI system.",
      "word_count": 49,
      "char_count": 432,
      "attention_fingerprint": [
        49.0,
        432.0,
        1.0,
        2.0,
        26.0
      ]
    },
    {
      "id": 1,
      "text": "</SEGMENT> The current model has limitations in context understanding and we're seeing issues with long conversations Speaker B: I agree.",
      "word_count": 20,
      "char_count": 137,
      "attention_fingerprint": [
        20.0,
        137.0,
        1.0,
        0.0,
        7.0
      ]
    },
    {
      "id": 2,
      "text": "From a technical perspective, we should look at attention mechanisms The research shows that transformer models with better attention patterns can handle longer contexts more effectively Speaker A: What about memory requirements Our current infrastructure might not support larger models We need to consider cost implications.",
      "word_count": 46,
      "char_count": 326,
      "attention_fingerprint": [
        46.0,
        326.0,
        1.0,
        1.0,
        17.0
      ]
    },
    {
      "id": 3,
      "text": "Speaker B: That's a good point We could implement a layered approach where we process information in chunks but maintain connections between them <CONNECT rule='Group by themes: technical discussion, resource concerns, action items'>This would be like a knowledge graph approach.",
      "word_count": 40,
      "char_count": 279,
      "attention_fingerprint": [
        40.0,
        279.0,
        1.0,
        2.0,
        19.0
      ]
    },
    {
      "id": 4,
      "text": "Speaker A: Interesting.",
      "word_count": 3,
      "char_count": 23,
      "attention_fingerprint": [
        3.0,
        23.0,
        1.0,
        0.0,
        2.0
      ]
    },
    {
      "id": 5,
      "text": "</CONNECT> instead of one massive context window, we create multiple smaller windows that are connected How would that work technically Speaker B: We could use attention patterns to identify natural boundaries in the text, then create overlapping segments The overlap ensures information can flow between segments - it's based on percolation theory Speaker A: I this approach.",
      "word_count": 57,
      "char_count": 376,
      "attention_fingerprint": [
        57.0,
        376.0,
        1.0,
        2.0,
        26.0
      ]
    },
    {
      "id": 6,
      "text": "Let's prototype it.",
      "word_count": 3,
      "char_count": 19,
      "attention_fingerprint": [
        3.0,
        19.0,
        1.0,
        0.0,
        1.0
      ]
    },
    {
      "id": 7,
      "text": "What are the next steps Speaker B: First, we need to implement the chunking algorithm Second, we need to extract attention patterns.",
      "word_count": 22,
      "char_count": 132,
      "attention_fingerprint": [
        22.0,
        132.0,
        1.0,
        2.0,
        8.0
      ]
    },
    {
      "id": 8,
      "text": "Third, we build the knowledge graph <ORGANIZE rule='Group by themes: technical discussion, resource concerns, action items'>Finally, we test reconstruction from the graph back to useful summaries.",
      "word_count": 26,
      "char_count": 196,
      "attention_fingerprint": [
        26.0,
        196.0,
        1.0,
        4.0,
        11.0
      ]
    },
    {
      "id": 9,
      "text": "</ORGANIZE>.",
      "word_count": 1,
      "char_count": 12,
      "attention_fingerprint": [
        1.0,
        12.0,
        1.0,
        0.0,
        1.0
      ]
    }
  ],
  "edges": [
    {
      "source": 0,
      "target": 1,
      "weight": 0.9994239211082458,
      "type": "semantic_similarity"
    },
    {
      "source": 0,
      "target": 2,
      "weight": 0.9995957016944885,
      "type": "semantic_similarity"
    },
    {
      "source": 0,
      "target": 3,
      "weight": 0.9995354413986206,
      "type": "semantic_similarity"
    },
    {
      "source": 0,
      "target": 4,
      "weight": 0.9986795783042908,
      "type": "semantic_similarity"
    },
    {
      "source": 0,
      "target": 5,
      "weight": 0.9992628693580627,
      "type": "semantic_similarity"
    },
    {
      "source": 0,
      "target": 6,
      "weight": 0.9977819323539734,
      "type": "semantic_similarity"
    },
    {
      "source": 0,
      "target": 7,
      "weight": 0.9985759854316711,
      "type": "semantic_similarity"
    },
    {
      "source": 0,
      "target": 8,
      "weight": 0.9996870756149292,
      "type": "semantic_similarity"
    },
    {
      "source": 0,
      "target": 9,
      "weight": 0.9960624575614929,
      "type": "semantic_similarity"
    },
    {
      "source": 1,
      "target": 2,
      "weight": 0.9999745488166809,
      "type": "semantic_similarity"
    },
    {
      "source": 1,
      "target": 3,
      "weight": 0.9998239278793335,
      "type": "semantic_similarity"
    },
    {
      "source": 1,
      "target": 4,
      "weight": 0.9986171722412109,
      "type": "semantic_similarity"
    },
    {
      "source": 1,
      "target": 5,
      "weight": 0.9998031258583069,
      "type": "semantic_similarity"
    },
    {
      "source": 1,
      "target": 6,
      "weight": 0.9989344477653503,
      "type": "semantic_similarity"
    },
    {
      "source": 1,
      "target": 7,
      "weight": 0.9996433258056641,
      "type": "semantic_similarity"
    },
    {
      "source": 1,
      "target": 8,
      "weight": 0.9996955990791321,
      "type": "semantic_similarity"
    },
    {
      "source": 1,
      "target": 9,
      "weight": 0.9947460293769836,
      "type": "semantic_similarity"
    },
    {
      "source": 2,
      "target": 3,
      "weight": 0.9998656511306763,
      "type": "semantic_similarity"
    },
    {
      "source": 2,
      "target": 4,
      "weight": 0.9985532760620117,
      "type": "semantic_similarity"
    },
    {
      "source": 2,
      "target": 5,
      "weight": 0.9998059272766113,
      "type": "semantic_similarity"
    },
    {
      "source": 2,
      "target": 6,
      "weight": 0.9986686706542969,
      "type": "semantic_similarity"
    },
    {
      "source": 2,
      "target": 7,
      "weight": 0.9995759129524231,
      "type": "semantic_similarity"
    },
    {
      "source": 2,
      "target": 8,
      "weight": 0.9998084306716919,
      "type": "semantic_similarity"
    },
    {
      "source": 2,
      "target": 9,
      "weight": 0.9947338104248047,
      "type": "semantic_similarity"
    },
    {
      "source": 3,
      "target": 4,
      "weight": 0.9989446997642517,
      "type": "semantic_similarity"
    },
    {
      "source": 3,
      "target": 5,
      "weight": 0.9999651908874512,
      "type": "semantic_similarity"
    },
    {
      "source": 3,
      "target": 6,
      "weight": 0.9985889792442322,
      "type": "semantic_similarity"
    },
    {
      "source": 3,
      "target": 7,
      "weight": 0.9996751546859741,
      "type": "semantic_similarity"
    },
    {
      "source": 3,
      "target": 8,
      "weight": 0.9997891187667847,
      "type": "semantic_similarity"
    },
    {
      "source": 3,
      "target": 9,
      "weight": 0.994994044303894,
      "type": "semantic_similarity"
    },
    {
      "source": 4,
      "target": 5,
      "weight": 0.9988030195236206,
      "type": "semantic_similarity"
    },
    {
      "source": 4,
      "target": 6,
      "weight": 0.9990217685699463,
      "type": "semantic_similarity"
    },
    {
      "source": 4,
      "target": 7,
      "weight": 0.9982903003692627,
      "type": "semantic_similarity"
    },
    {
      "source": 4,
      "target": 8,
      "weight": 0.9986139535903931,
      "type": "semantic_similarity"
    },
    {
      "source": 4,
      "target": 9,
      "weight": 0.998137891292572,
      "type": "semantic_similarity"
    },
    {
      "source": 5,
      "target": 6,
      "weight": 0.9986220002174377,
      "type": "semantic_similarity"
    },
    {
      "source": 5,
      "target": 7,
      "weight": 0.9997974038124084,
      "type": "semantic_similarity"
    },
    {
      "source": 5,
      "target": 8,
      "weight": 0.9996331930160522,
      "type": "semantic_similarity"
    },
    {
      "source": 5,
      "target": 9,
      "weight": 0.9944422841072083,
      "type": "semantic_similarity"
    },
    {
      "source": 6,
      "target": 7,
      "weight": 0.99883633852005,
      "type": "semantic_similarity"
    },
    {
      "source": 6,
      "target": 8,
      "weight": 0.9983896017074585,
      "type": "semantic_similarity"
    },
    {
      "source": 6,
      "target": 9,
      "weight": 0.9963818192481995,
      "type": "semantic_similarity"
    },
    {
      "source": 7,
      "target": 8,
      "weight": 0.9994234442710876,
      "type": "semantic_similarity"
    },
    {
      "source": 7,
      "target": 9,
      "weight": 0.9934711456298828,
      "type": "semantic_similarity"
    },
    {
      "source": 8,
      "target": 9,
      "weight": 0.9952452182769775,
      "type": "semantic_similarity"
    }
  ],
  "metadata": {
    "model_type": "ollama",
    "n_nodes": 10,
    "n_edges": 45,
    "similarity_threshold": 0.3
  },
  "timestamp": "20250713_205218",
  "test_name": "complete_system_test"
}